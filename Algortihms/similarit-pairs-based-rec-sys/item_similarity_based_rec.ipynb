{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install polars"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YS2UTX0OxH4c",
        "outputId": "bcfd6183-e106-4f2f-fa16-22fa2f4510ca"
      },
      "id": "YS2UTX0OxH4c",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.10/dist-packages (0.17.3)\n",
            "Requirement already satisfied: typing_extensions>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from polars) (4.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pickle5\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lm91aHcNxI0g",
        "outputId": "072eb72d-8e60-415c-abd9-43a471cbea64"
      },
      "id": "lm91aHcNxI0g",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pickle5\n",
            "  Downloading pickle5-0.0.11.tar.gz (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.1/132.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pickle5\n",
            "  Building wheel for pickle5 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pickle5: filename=pickle5-0.0.11-cp310-cp310-linux_x86_64.whl size=256403 sha256=9a80d0eedd1f568a96525f08509601fd02b2665797206df9b38f1d1b475833e7\n",
            "  Stored in directory: /root/.cache/pip/wheels/7d/14/ef/4aab19d27fa8e58772be5c71c16add0426acf9e1f64353235c\n",
            "Successfully built pickle5\n",
            "Installing collected packages: pickle5\n",
            "Successfully installed pickle5-0.0.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UiHLyKqcxSfz"
      },
      "id": "UiHLyKqcxSfz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {'train_session_num': 12899779}"
      ],
      "metadata": {
        "id": "996VeQaqxSiZ"
      },
      "id": "996VeQaqxSiZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import polars as pl\n",
        "from gensim.test.utils import common_texts\n",
        "from gensim.models import Word2Vec\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from heapq import nlargest\n",
        "import pickle5 as pickle\n",
        "import os\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "import numpy as np\n",
        "import random\n",
        "import copy\n",
        "from collections import defaultdict, Counter\n",
        "import gc\n"
      ],
      "metadata": {
        "id": "jDsBRL1uxI3V"
      },
      "id": "jDsBRL1uxI3V",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccd0522e",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2022-11-03T11:11:43.906919Z",
          "iopub.status.busy": "2022-11-03T11:11:43.906368Z",
          "iopub.status.idle": "2022-11-03T11:11:43.919631Z",
          "shell.execute_reply": "2022-11-03T11:11:43.918247Z"
        },
        "papermill": {
          "duration": 0.02305,
          "end_time": "2022-11-03T11:11:43.922292",
          "exception": false,
          "start_time": "2022-11-03T11:11:43.899242",
          "status": "completed"
        },
        "tags": [],
        "id": "ccd0522e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qetBG96sxH7L"
      },
      "id": "qetBG96sxH7L",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01ce3b91",
      "metadata": {
        "papermill": {
          "duration": 0.005204,
          "end_time": "2022-11-03T11:11:43.933440",
          "exception": false,
          "start_time": "2022-11-03T11:11:43.928236",
          "status": "completed"
        },
        "tags": [],
        "id": "01ce3b91"
      },
      "outputs": [],
      "source": [
        "def load_datasets_and_mappings():\n",
        "    \"\"\"Load training data and id-to-type mappings.\"\"\"\n",
        "    training_data = pl.read_parquet('train.parquet')\n",
        "    with open('id2type.pkl', \"rb\") as fh:\n",
        "        id_to_type_mapping = pickle.load(fh)\n",
        "    with open('type2id.pkl', \"rb\") as fh:\n",
        "        type_to_id_mapping = pickle.load(fh)\n",
        "    return training_data.to_pandas(), id_to_type_mapping, type_to_id_mapping\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_data, id_to_type_mapping, _ = load_datasets_and_mappings()"
      ],
      "metadata": {
        "id": "P7JTzLNyxVsx"
      },
      "id": "P7JTzLNyxVsx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_training_data(training_data, config):\n",
        "    \"\"\"Preprocess the training data.\"\"\"\n",
        "    training_data['aid'] = training_data['aid'].astype('int32').astype('str')\n",
        "\n",
        "    # Randomly sample sessions for training\n",
        "    sampled_sessions = random.sample(list(training_data['session'].unique()), config['train_session_num'])\n",
        "    training_data = training_data.query('session in @sampled_sessions').reset_index(drop=True)\n",
        "\n",
        "    training_data['time_stamp'] = pd.to_datetime(training_data['ts'], unit='s').dt.strftime('%Y-%m-%d')\n",
        "\n",
        "    return training_data"
      ],
      "metadata": {
        "id": "7lV6rkpQxVvF"
      },
      "id": "7lV6rkpQxVvF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = preprocess_training_data(training_data, config)"
      ],
      "metadata": {
        "id": "6m8O8DDRxVxn"
      },
      "id": "6m8O8DDRxVxn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "del sampled_sessions\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "jKJAJZE9xkMO"
      },
      "id": "jKJAJZE9xkMO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_similarity_pairs(data):\n",
        "    \"\"\"Generate pair-wise interactions for similarity computation.\"\"\"\n",
        "    data = data.sort_values(by=['session', 'ts'])\n",
        "    data['next_aid'] = data['aid'].shift(-1)\n",
        "    data['session_day'] = data['session'].astype('str') + '_' + data['time_stamp']\n",
        "    data['session_day_count'] = data['session_day'].map(data['session_day'].value_counts())\n",
        "    data['ranking'] = data.groupby(['session_day'])['ts'].rank(method='first', ascending=True)\n",
        "    data = data.query('session_day_count!=ranking').reset_index(drop=True)\n",
        "\n",
        "    similar_aids = data.groupby('aid').apply(lambda df: Counter(df.next_aid).most_common(50)).to_dict()\n",
        "    similar_aids = {aid: Counter(dict(top)) for aid, top in similar_aids.items()}\n",
        "\n",
        "    return similar_aids"
      ],
      "metadata": {
        "id": "aWQqkKsKxkPR"
      },
      "id": "aWQqkKsKxkPR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similar_items = generate_similarity_pairs(training_data)"
      ],
      "metadata": {
        "id": "-b15nOEBxkRf"
      },
      "id": "-b15nOEBxkRf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del training_data\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "UMWaiBarxkTy"
      },
      "id": "UMWaiBarxkTy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_preprocess_test_data():\n",
        "    \"\"\"Load and preprocess test data.\"\"\"\n",
        "    test_data = pl.read_parquet('test.parquet')\n",
        "    test_data = test_data.to_pandas()\n",
        "    test_data['aid'] = test_data['aid'].astype('int32').astype('str')\n",
        "    test_data['time_stamp'] = pd.to_datetime(test_data['ts'],unit='s').dt.strftime('%Y-%m-%d')\n",
        "    test_data = test_data.sort_values([\"session\", \"type\", \"ts\"])\n",
        "    session_to_item_ids = test_data.groupby('session')['aid'].agg(list).to_dict()\n",
        "    return session_to_item_ids"
      ],
      "metadata": {
        "id": "-ew_UAa3xkWA"
      },
      "id": "-ew_UAa3xkWA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_recommendations(session_to_item_ids, similar_items, popular_items):\n",
        "    \"\"\"Generate item recommendations for each session.\"\"\"\n",
        "    session_ids = []\n",
        "    recommended_item_lists = []\n",
        "    for session_id, session_items in tqdm(session_to_item_ids.items()):\n",
        "        recommended_items = recommend_items(session_items, similar_items, popular_items)\n",
        "        session_ids.append(session_id)\n",
        "        recommended_item_lists.append(recommended_items)\n",
        "\n",
        "    return session_ids, recommended_item_lists"
      ],
      "metadata": {
        "id": "esD-_3jgxkYQ"
      },
      "id": "esD-_3jgxkYQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_submission_file(session_ids, recommended_item_lists, id_to_type_mapping):\n",
        "    \"\"\"Create a submission file with the recommended items for each session type.\"\"\"\n",
        "    submission_df = pd.DataFrame()\n",
        "    submission_df['session_type'] = session_ids\n",
        "    submission_df['labels'] = [' '.join([str(item) for item in item_list]) for item_list in recommended_item_lists]\n",
        "\n",
        "    submission_list = []\n",
        "    for type_ in [0,1,2]:\n",
        "        type_specific_df = submission_df.copy()\n",
        "        type_specific_df['session_type'] = type_specific_df['session_type'].apply(lambda x: f'{x}_{id_to_type_mapping[type_]}')\n",
        "        submission_list.append(type_specific_df)\n",
        "    submission_df = pd.concat(submission_list,axis=0)\n",
        "\n",
        "    submission_df.to_csv('submission.csv',index=False)\n",
        "    return submission_df"
      ],
      "metadata": {
        "id": "GtQ_ip2Gxvgm"
      },
      "id": "GtQ_ip2Gxvgm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "session_to_item_ids = load_and_preprocess_test_data()\n",
        "popular_items = list(training_data['aid'].value_counts().index)\n",
        "session_ids, recommended_item_lists = generate_recommendations(session_to_item_ids, similar_items, popular_items)\n",
        "submission_df=create_submission_file(session_ids, recommended_item_lists, id_to_type_mapping)"
      ],
      "metadata": {
        "id": "IyNjKuC5xvjY"
      },
      "id": "IyNjKuC5xvjY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UNFvnXHSxv9a"
      },
      "id": "UNFvnXHSxv9a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be465bb8",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-03T11:37:09.739576Z",
          "iopub.status.busy": "2022-11-03T11:37:09.739222Z",
          "iopub.status.idle": "2022-11-03T11:37:09.904034Z",
          "shell.execute_reply": "2022-11-03T11:37:09.903130Z"
        },
        "papermill": {
          "duration": 0.185361,
          "end_time": "2022-11-03T11:37:09.906113",
          "exception": false,
          "start_time": "2022-11-03T11:37:09.720752",
          "status": "completed"
        },
        "tags": [],
        "id": "be465bb8",
        "outputId": "5821116b-7f7f-4419-f30c-714f0040d04c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>session_type</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12899779_clicks</td>\n",
              "      <td>59625 1243845 1223875 1266598 1275942 1272658 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12899779_carts</td>\n",
              "      <td>59625 1243845 1223875 1266598 1275942 1272658 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12899779_orders</td>\n",
              "      <td>59625 1243845 1223875 1266598 1275942 1272658 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>12899780_clicks</td>\n",
              "      <td>1142000 736515 582732 973453 1502122 889686 48...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12899780_carts</td>\n",
              "      <td>1142000 736515 582732 973453 1502122 889686 48...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      session_type                                             labels\n",
              "0  12899779_clicks  59625 1243845 1223875 1266598 1275942 1272658 ...\n",
              "1   12899779_carts  59625 1243845 1223875 1266598 1275942 1272658 ...\n",
              "2  12899779_orders  59625 1243845 1223875 1266598 1275942 1272658 ...\n",
              "3  12899780_clicks  1142000 736515 582732 973453 1502122 889686 48...\n",
              "4   12899780_carts  1142000 736515 582732 973453 1502122 889686 48..."
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "submission_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c64b6894",
      "metadata": {
        "papermill": {
          "duration": 0.017148,
          "end_time": "2022-11-03T11:37:09.941771",
          "exception": false,
          "start_time": "2022-11-03T11:37:09.924623",
          "status": "completed"
        },
        "tags": [],
        "id": "c64b6894"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 1536.924218,
      "end_time": "2022-11-03T11:37:13.184493",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2022-11-03T11:11:36.260275",
      "version": "2.3.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}